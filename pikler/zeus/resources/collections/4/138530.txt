Parallel computing     parallel computing is a form of computation in which many instructions are carried out simultaneously ( termed `` in parallel '' ) , depending on the theory that large problems can often be divided into smaller ones , and then solved concurrently ( `` in parallel '' ) . there are several different forms of parallel computing : 1. bit-level parallelism , 1. instruction-level parallelism , 1. data parallelism , 1. task parallelism . it has been used for many years , mainly in high-performance computing , with a great increase in its use in recent years , due to the physical constraints preventing frequency scaling . parallel computing has become the main model in computer architecture , mainly in the form of multi-core processors . however , in recent years , power consumption by parallel computers has become a concern . parallel computers can be classified according to the level at which the hardware supports parallelismâ€”with multi-core and multi-processor computers having multiple processing elements inside a single machine , while clusters , blades , mpps , and grids use multiple computers to work on the same task .