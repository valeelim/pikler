Data parallelism     data parallelism ( also known as loop-level parallelism ) is a form of parallel computing for multiple processors using a technique for distributing the data across different parallel processor nodes . it contrasts to task parallelism as another form of parallelism . in a multiprocessor system where each one is executing a single set of instructions , data parallelism is achieved when each processor performs the same task on different pieces of distributed data . in some situations , a single execution thread controls operations on all pieces of data . in others , different threads control the operation , but they execute the same code . for example , if we are running code on a 2-processor system ( cpus a and b ) in a parallel computing environment , and we want to do a task on some data d , it is possible to tell cpu a to do that task on one part of d and cpu b on another part of d simultaneously ( at the same time ) , in order to reduce the runtime of the execution . data parallelism is used by many applications especially data processing applications ; one of the examples is database applications . most real programs use a combination of data parallelism and task parallelism .