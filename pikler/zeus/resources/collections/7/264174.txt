Bayes' theorem    bayes ' theorem in probability theory and applications , bayes ' theorem shows the relation between a conditional probability and its reverse form . for example , the probability of a hypothesis given some observed pieces of evidence and the probability of that evidence given the hypothesis . this theorem is named after thomas bayes ( or `` bays '' ) and often called bayes ' law or bayes ' rule . the equation used is : where : - p ( `` a '' ) is the prior probability or marginal probability of `` a '' . it is `` prior '' in the sense that it does not take into account any information about '' b '' . - p ( `` a '' | '' b '' ) is the conditional probability of `` a '' , given `` b '' . it is also called the posterior probability because it is derived from or depends upon the specified value of '' b '' . - p ( `` b '' | '' a '' ) is the conditional probability of `` b '' given `` a '' . it is also called the likelihood . - p ( `` b '' ) is the prior or marginal probability of `` b '' , and acts as a normalizing constant . a simple example is as follows : there is a 40 % chance of it raining on sunday . if it rains on sunday , there is a 10 % chance it will rain on monday . if it did n't rain on sunday , there 's an 80 % chance it will rain on monday .